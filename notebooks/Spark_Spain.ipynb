{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML with Pyspark\n",
    "+ classify/predict winning team \n",
    "\n",
    "### Data Source\n",
    "+ https://www.kaggle.com/hikne707/big-five-european-soccer-leagues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our Packages\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master='local[2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.21.167.156:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=PySparkShell>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Spark_Spain\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### workflow\n",
    "* Data Prep\n",
    "+ Feature Engineering\n",
    "+ Build Model \n",
    "+ Evaluate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task \n",
    "+ predict what team will win in the spain league/country based on parameters\n",
    "+ multi-classification problem win, lose, or tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our dataset\n",
    "df = spark.read.csv(\"D:/Senior/Capstone/data-science-enviroment/data/Leagues/Spain_league_V1.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+-------+\n",
      "|Round|                Date|Team_1|Team_2|Year|Country|FT_Team_1|FT_Team_2|HT_Team_1|HT_Team_2|GGD|Team_1_(pts)|Team_2_(pts)|Outcome|\n",
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+-------+\n",
      "|    1|(Sat) 2 Sep 1995 ...|   156|   210|1995|      1|        3|        0|        2|        0|  3|           3|           0|      1|\n",
      "|    1|(Sat) 2 Sep 1995 ...|   187|    21|1995|      1|        3|        0|        3|        0|  3|           3|           0|      1|\n",
      "|    1|(Sun) 3 Sep 1995 ...|    30|   164|1995|      1|        4|        0|        2|        0|  4|           3|           0|      1|\n",
      "|    1|(Sun) 3 Sep 1995 ...|    31|   165|1995|      1|        4|        1|        1|        1|  3|           3|           0|      1|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   152|   172|1995|      1|        0|        1|        0|        0|  1|           0|           3|      2|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   155|   203|1995|      1|        3|        1|        2|        1|  2|           3|           0|      1|\n",
      "|    1|(Sun) 3 Sep 1995 ...|    54|   160|1995|      1|        1|        1|        1|        1|  0|           1|           1|      3|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   182|    52|1995|      1|        0|        1|        0|        0|  1|           0|           3|      2|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   166|    82|1995|      1|        0|        2|        0|        0|  2|           0|           3|      2|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   158|   161|1995|      1|        1|        5|        0|        1|  4|           0|           3|      2|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   167|   163|1995|      1|        1|        0|        1|        0|  1|           3|           0|      1|\n",
      "|    2|(Sat) 9 Sep 1995 ...|    21|   182|1995|      1|        3|        2|        2|        1|  1|           3|           0|      1|\n",
      "|    2|(Sat) 9 Sep 1995 ...|    82|    54|1995|      1|        2|        2|        1|        1|  0|           1|           1|      3|\n",
      "|    2|(Sat) 9 Sep 1995 ...|   160|   167|1995|      1|        3|        1|        2|        0|  2|           3|           0|      1|\n",
      "|    2|(Sat) 9 Sep 1995 ...|   161|    30|1995|      1|        1|        2|        0|        0|  1|           0|           3|      2|\n",
      "|    2|(Sun) 10 Sep 1995...|   172|   156|1995|      1|        4|        0|        2|        0|  4|           3|           0|      1|\n",
      "|    2|(Sun) 10 Sep 1995...|   163|   158|1995|      1|        2|        0|        1|        0|  2|           3|           0|      1|\n",
      "|    2|(Sun) 10 Sep 1995...|   203|   152|1995|      1|        0|        1|        0|        0|  1|           0|           3|      2|\n",
      "|    2|(Sun) 10 Sep 1995...|   164|    31|1995|      1|        0|        4|        0|        0|  4|           0|           3|      2|\n",
      "|    2|(Sun) 10 Sep 1995...|   165|   187|1995|      1|        2|        0|        1|        0|  2|           3|           0|      1|\n",
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data prieview\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Round', 'Date', 'Team_1', 'Team_2', 'Year', 'Country', 'FT_Team_1', 'FT_Team_2', 'HT_Team_1', 'HT_Team_2', 'GGD', 'Team_1_(pts)', 'Team_2_(pts)', 'Outcome']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Round', 'int'),\n",
       " ('Date', 'string'),\n",
       " ('Team_1', 'int'),\n",
       " ('Team_2', 'int'),\n",
       " ('Year', 'int'),\n",
       " ('Country', 'int'),\n",
       " ('FT_Team_1', 'int'),\n",
       " ('FT_Team_2', 'int'),\n",
       " ('HT_Team_1', 'int'),\n",
       " ('HT_Team_2', 'int'),\n",
       " ('GGD', 'int'),\n",
       " ('Team_1_(pts)', 'int'),\n",
       " ('Team_2_(pts)', 'int'),\n",
       " ('Outcome', 'int')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes\n",
    "# inferschema changes type string to int, creates less work\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+------------------+------------------+------------------+-------+------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|             Round|                Date|            Team_1|            Team_2|              Year|Country|         FT_Team_1|         FT_Team_2|         HT_Team_1|          HT_Team_2|               GGD|      Team_1_(pts)|      Team_2_(pts)|           Outcome|\n",
      "+-------+------------------+--------------------+------------------+------------------+------------------+-------+------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|              9554|                9554|              9554|              9554|              9554|   9554|              9554|              9554|              9554|               9554|              9554|              9554|              9554|              9554|\n",
      "|   mean|19.537994557253505|                null|135.84435838392295|135.88371362779986|2006.6644337450282|    1.0|1.5730584048566045| 1.118589072639732|0.6946828553485451|0.48419510152815576|  1.35001046682018| 1.688193426836927|1.0583001884027632|1.7752773707347709|\n",
      "| stddev|11.063375327122287|                null|   55.452060110259|55.434325949188285| 7.226025739195574|    0.0| 1.313017115943747|1.1187541569425545|0.8434692487609308| 0.6972387600002166|1.2135856883043108|1.3068087892319449|1.2442067909236467|0.8254128965571996|\n",
      "|    min|                 1|(Fri) 1 Apr 2016 ...|                21|                21|              1995|      1|                 0|                 0|                 0|                  0|                 0|                 0|                 0|                 1|\n",
      "|    max|                42|(Wed) 9 May 2018 ...|               224|               224|              2019|      1|                10|                 8|                 6|                  6|                 8|                 3|                 3|                 3|\n",
      "+-------+------------------+--------------------+------------------+------------------+------------------+-------+------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#descriptive summary\n",
    "print(df.describe().show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Outcome|count|\n",
      "+-------+-----+\n",
      "|      1| 4569|\n",
      "|      3| 2422|\n",
      "|      2| 2563|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Value Count (check if dataSet is balance)\n",
    "df.groupBy('Outcome').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "* Numericcal values\n",
    "* Vectorization (the process of converting an algorithm from operating on a single value at a time to operating on a set of values (vector) at one time.)\n",
    "* Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml\n",
    "# load Ml packages\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2nd half goals full time - half time\n",
    "df= df.withColumn(\"H2_Team_1\", df['FT_Team_1']-df['HT_Team_1'])\n",
    "df= df.withColumn(\"H2_Team_2\", df['FT_Team_2']-df['HT_Team_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename HT to represent 1/2 halves, sorry for the redundency spark beginner\n",
    "df= df.withColumnRenamed('HT_Team_1','H1_Team_1')\n",
    "df= df.withColumnRenamed('HT_Team_2','H1_Team_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goal difference given, creating + for home win and - for away win\n",
    "df= df.withColumn('FT_GD', df['FT_Team_1']-df['FT_Team_2'])\n",
    "df= df.withColumn('H1_GD', df['H1_Team_1']-df['H1_Team_2'])\n",
    "df= df.withColumn('H2_GD', df['FT_GD']-df['H1_GD'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Round', 'Date', 'Team_1', 'Team_2', 'Year', 'Country', 'FT_Team_1', 'FT_Team_2', 'H1_Team_1', 'H1_Team_2', 'GGD', 'Team_1_(pts)', 'Team_2_(pts)', 'Outcome', 'H2_Team_1', 'H2_Team_2', 'FT_GD', 'H1_GD', 'H2_GD']\n"
     ]
    }
   ],
   "source": [
    "# addded colums include: \n",
    "#second half goal difference for home and away\n",
    "#Full time goal differnce (displays negative if away team scores more)\n",
    "# goals sccored second half \n",
    "# I thought about stripping the date in this case but i dont find it nesscary since we already have the year to work with, date will get dropped later on.\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearranging column so the output = outcome is at the end\n",
    "df = df.select('Round', 'Date', 'Team_1', 'Team_2', 'Year', 'Country', 'FT_Team_1', 'FT_Team_2', 'H1_Team_1', 'H1_Team_2', 'GGD', 'Team_1_(pts)', 'Team_2_(pts)', 'H2_Team_1', 'H2_Team_2', 'FT_GD', 'H1_GD', 'H2_GD', 'Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+---------+---------+-----+-----+-----+-------+\n",
      "|Round|                Date|Team_1|Team_2|Year|Country|FT_Team_1|FT_Team_2|H1_Team_1|H1_Team_2|GGD|Team_1_(pts)|Team_2_(pts)|H2_Team_1|H2_Team_2|FT_GD|H1_GD|H2_GD|Outcome|\n",
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+---------+---------+-----+-----+-----+-------+\n",
      "|    1|(Sat) 2 Sep 1995 ...|   156|   210|1995|      1|        3|        0|        2|        0|  3|           3|           0|        1|        0|    3|    2|    1|      1|\n",
      "|    1|(Sat) 2 Sep 1995 ...|   187|    21|1995|      1|        3|        0|        3|        0|  3|           3|           0|        0|        0|    3|    3|    0|      1|\n",
      "|    1|(Sun) 3 Sep 1995 ...|    30|   164|1995|      1|        4|        0|        2|        0|  4|           3|           0|        2|        0|    4|    2|    2|      1|\n",
      "|    1|(Sun) 3 Sep 1995 ...|    31|   165|1995|      1|        4|        1|        1|        1|  3|           3|           0|        3|        0|    3|    0|    3|      1|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   152|   172|1995|      1|        0|        1|        0|        0|  1|           0|           3|        0|        1|   -1|    0|   -1|      2|\n",
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+---------+---------+-----+-----+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see home and away team have been label enconded already and converted into numbers(this data was worked on before bringinto jupyter notebook, it is not the raw file, all that is left to do is the date column and as I mention above the initial plan was to drop it but month and year(which we already) can be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the date column to get month, then label encode month\n",
    "from pyspark.sql.functions import split\n",
    "df = df.withColumn('Month', split(df['Date'],' ').getItem(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the string Month into numbers\n",
    "# label encoding\n",
    "monthEncoder = StringIndexer(inputCol='Month',outputCol='Game_Month').fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = monthEncoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+---------+---------+-----+-----+-----+-------+-----+----------+\n",
      "|Round|                Date|Team_1|Team_2|Year|Country|FT_Team_1|FT_Team_2|H1_Team_1|H1_Team_2|GGD|Team_1_(pts)|Team_2_(pts)|H2_Team_1|H2_Team_2|FT_GD|H1_GD|H2_GD|Outcome|Month|Game_Month|\n",
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+---------+---------+-----+-----+-----+-------+-----+----------+\n",
      "|    1|(Sat) 2 Sep 1995 ...|   156|   210|1995|      1|        3|        0|        2|        0|  3|           3|           0|        1|        0|    3|    2|    1|      1|  Sep|       5.0|\n",
      "|    1|(Sat) 2 Sep 1995 ...|   187|    21|1995|      1|        3|        0|        3|        0|  3|           3|           0|        0|        0|    3|    3|    0|      1|  Sep|       5.0|\n",
      "|    1|(Sun) 3 Sep 1995 ...|    30|   164|1995|      1|        4|        0|        2|        0|  4|           3|           0|        2|        0|    4|    2|    2|      1|  Sep|       5.0|\n",
      "|    1|(Sun) 3 Sep 1995 ...|    31|   165|1995|      1|        4|        1|        1|        1|  3|           3|           0|        3|        0|    3|    0|    3|      1|  Sep|       5.0|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   152|   172|1995|      1|        0|        1|        0|        0|  1|           0|           3|        0|        1|   -1|    0|   -1|      2|  Sep|       5.0|\n",
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+---------+---------+-----+-----+-----+-------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apr', 'Jan', 'Mar', 'Feb', 'Oct', 'Sep', 'Nov', 'May', 'Dec', 'Aug', 'Jun']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get encoded labels, annoying since labels are not from 0-11 jan-dec\n",
    "monthEncoder.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Round', 'Date', 'Team_1', 'Team_2', 'Year', 'Country', 'FT_Team_1', 'FT_Team_2', 'H1_Team_1', 'H1_Team_2', 'GGD', 'Team_1_(pts)', 'Team_2_(pts)', 'H2_Team_1', 'H2_Team_2', 'FT_GD', 'H1_GD', 'H2_GD', 'Outcome', 'Month', 'Game_Month']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_features = ['Round', 'Team_1', 'Team_2', 'Year', 'Country', 'FT_Team_1', 'FT_Team_2', 'H1_Team_1', 'H1_Team_2', 'GGD', 'Team_1_(pts)', 'Team_2_(pts)', 'H2_Team_1', 'H2_Team_2', 'FT_GD', 'H1_GD', 'H2_GD', 'Game_Month', 'Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorAssembly\n",
    "vec_assembler = VectorAssembler(inputCols=required_features,outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sticking entire feature required in a vector which I will be using to Model \n",
    "vec_df = vec_assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+---------+---------+-----+-----+-----+-------+-----+----------+--------------------+\n",
      "|Round|                Date|Team_1|Team_2|Year|Country|FT_Team_1|FT_Team_2|H1_Team_1|H1_Team_2|GGD|Team_1_(pts)|Team_2_(pts)|H2_Team_1|H2_Team_2|FT_GD|H1_GD|H2_GD|Outcome|Month|Game_Month|            features|\n",
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+---------+---------+-----+-----+-----+-------+-----+----------+--------------------+\n",
      "|    1|(Sat) 2 Sep 1995 ...|   156|   210|1995|      1|        3|        0|        2|        0|  3|           3|           0|        1|        0|    3|    2|    1|      1|  Sep|       5.0|[1.0,156.0,210.0,...|\n",
      "|    1|(Sat) 2 Sep 1995 ...|   187|    21|1995|      1|        3|        0|        3|        0|  3|           3|           0|        0|        0|    3|    3|    0|      1|  Sep|       5.0|[1.0,187.0,21.0,1...|\n",
      "|    1|(Sun) 3 Sep 1995 ...|    30|   164|1995|      1|        4|        0|        2|        0|  4|           3|           0|        2|        0|    4|    2|    2|      1|  Sep|       5.0|[1.0,30.0,164.0,1...|\n",
      "|    1|(Sun) 3 Sep 1995 ...|    31|   165|1995|      1|        4|        1|        1|        1|  3|           3|           0|        3|        0|    3|    0|    3|      1|  Sep|       5.0|[1.0,31.0,165.0,1...|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   152|   172|1995|      1|        0|        1|        0|        0|  1|           0|           3|        0|        1|   -1|    0|   -1|      2|  Sep|       5.0|[1.0,152.0,172.0,...|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   155|   203|1995|      1|        3|        1|        2|        1|  2|           3|           0|        1|        0|    2|    1|    1|      1|  Sep|       5.0|[1.0,155.0,203.0,...|\n",
      "|    1|(Sun) 3 Sep 1995 ...|    54|   160|1995|      1|        1|        1|        1|        1|  0|           1|           1|        0|        0|    0|    0|    0|      3|  Sep|       5.0|[1.0,54.0,160.0,1...|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   182|    52|1995|      1|        0|        1|        0|        0|  1|           0|           3|        0|        1|   -1|    0|   -1|      2|  Sep|       5.0|[1.0,182.0,52.0,1...|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   166|    82|1995|      1|        0|        2|        0|        0|  2|           0|           3|        0|        2|   -2|    0|   -2|      2|  Sep|       5.0|[1.0,166.0,82.0,1...|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   158|   161|1995|      1|        1|        5|        0|        1|  4|           0|           3|        1|        4|   -4|   -1|   -3|      2|  Sep|       5.0|[1.0,158.0,161.0,...|\n",
      "|    1|(Sun) 3 Sep 1995 ...|   167|   163|1995|      1|        1|        0|        1|        0|  1|           3|           0|        0|        0|    1|    1|    0|      1|  Sep|       5.0|[1.0,167.0,163.0,...|\n",
      "|    2|(Sat) 9 Sep 1995 ...|    21|   182|1995|      1|        3|        2|        2|        1|  1|           3|           0|        1|        1|    1|    1|    0|      1|  Sep|       5.0|[2.0,21.0,182.0,1...|\n",
      "|    2|(Sat) 9 Sep 1995 ...|    82|    54|1995|      1|        2|        2|        1|        1|  0|           1|           1|        1|        1|    0|    0|    0|      3|  Sep|       5.0|[2.0,82.0,54.0,19...|\n",
      "|    2|(Sat) 9 Sep 1995 ...|   160|   167|1995|      1|        3|        1|        2|        0|  2|           3|           0|        1|        1|    2|    2|    0|      1|  Sep|       5.0|[2.0,160.0,167.0,...|\n",
      "|    2|(Sat) 9 Sep 1995 ...|   161|    30|1995|      1|        1|        2|        0|        0|  1|           0|           3|        1|        2|   -1|    0|   -1|      2|  Sep|       5.0|[2.0,161.0,30.0,1...|\n",
      "|    2|(Sun) 10 Sep 1995...|   172|   156|1995|      1|        4|        0|        2|        0|  4|           3|           0|        2|        0|    4|    2|    2|      1|  Sep|       5.0|[2.0,172.0,156.0,...|\n",
      "|    2|(Sun) 10 Sep 1995...|   163|   158|1995|      1|        2|        0|        1|        0|  2|           3|           0|        1|        0|    2|    1|    1|      1|  Sep|       5.0|[2.0,163.0,158.0,...|\n",
      "|    2|(Sun) 10 Sep 1995...|   203|   152|1995|      1|        0|        1|        0|        0|  1|           0|           3|        0|        1|   -1|    0|   -1|      2|  Sep|       5.0|[2.0,203.0,152.0,...|\n",
      "|    2|(Sun) 10 Sep 1995...|   164|    31|1995|      1|        0|        4|        0|        0|  4|           0|           3|        0|        4|   -4|    0|   -4|      2|  Sep|       5.0|[2.0,164.0,31.0,1...|\n",
      "|    2|(Sun) 10 Sep 1995...|   165|   187|1995|      1|        2|        0|        1|        0|  2|           3|           0|        1|        0|    2|    1|    1|      1|  Sep|       5.0|[2.0,165.0,187.0,...|\n",
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+---------+---------+-----+-----+-----+-------+-----+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = vec_df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6648"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "+ Pyspark.ml: Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic model\n",
    "lr = LogisticRegression(featuresCol='features',labelCol='Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+---------+---------+-----+-----+-----+-------+-----+----------+--------------------+--------------------+--------------------+----------+\n",
      "|Round|                Date|Team_1|Team_2|Year|Country|FT_Team_1|FT_Team_2|H1_Team_1|H1_Team_2|GGD|Team_1_(pts)|Team_2_(pts)|H2_Team_1|H2_Team_2|FT_GD|H1_GD|H2_GD|Outcome|Month|Game_Month|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+---------+---------+-----+-----+-----+-------+-----+----------+--------------------+--------------------+--------------------+----------+\n",
      "|    1|(Fri) 17 Aug 2018...|   102|   166|2018|      1|        0|        0|        0|        0|  0|           1|           1|        0|        0|    0|    0|    0|      3|  Aug|       9.0|(19,[0,1,2,3,4,10...|[-5132.4851158264...|   [0.0,0.0,0.0,1.0]|       3.0|\n",
      "|    1|(Fri) 17 Aug 2018...|   160|   125|2018|      1|        0|        3|        0|        1|  3|           0|           3|        0|        2|   -3|   -1|   -2|      2|  Aug|       9.0|[1.0,160.0,125.0,...|[-5132.8649300937...|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|    1|(Fri) 19 Aug 2016...|   156|   173|2016|      1|        2|        1|        0|        0|  1|           3|           0|        2|        1|    1|    0|    1|      1|  Aug|       9.0|[1.0,156.0,173.0,...|[-5127.7750910015...|[0.0,1.0,0.0,2.61...|       1.0|\n",
      "|    1|(Mon) 1 Sep 1997 ...|   166|   160|1997|      1|        1|        3|        1|        0|  2|           0|           3|        0|        3|   -2|    1|   -3|      2|  Sep|       5.0|[1.0,166.0,160.0,...|[-5079.5944439100...|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|    1|(Mon) 20 Aug 2012...|   158|   104|2012|      1|        1|        0|        0|        0|  1|           3|           0|        1|        0|    1|    0|    1|      1|  Aug|       9.0|[1.0,158.0,104.0,...|[-5117.1766533205...|[0.0,1.0,0.0,2.00...|       1.0|\n",
      "|    1|(Mon) 22 Aug 2016...|   152|    49|2016|      1|        0|        1|        0|        0|  1|           0|           3|        0|        1|   -1|    0|   -1|      2|  Aug|       9.0|[1.0,152.0,49.0,2...|[-5127.2188066969...|[0.0,0.0,1.0,2.63...|       2.0|\n",
      "|    1|(Mon) 25 Aug 2014...|   158|    31|2014|      1|        0|        0|        0|        0|  0|           1|           1|        0|        0|    0|    0|    0|      3|  Aug|       9.0|(19,[0,1,2,3,4,10...|[-5122.0905955839...|   [0.0,0.0,0.0,1.0]|       3.0|\n",
      "|    1|(Mon) 28 Aug 2006...|   152|    82|2006|      1|        2|        3|        1|        0|  1|           0|           3|        1|        3|   -1|    1|   -2|      2|  Aug|       9.0|[1.0,152.0,82.0,2...|[-5102.4070137056...|[0.0,0.0,1.0,1.86...|       2.0|\n",
      "|    1|(Sat) 17 Aug 2013...|   210|   134|2013|      1|        1|        0|        0|        0|  1|           3|           0|        1|        0|    1|    0|    1|      1|  Aug|       9.0|[1.0,210.0,134.0,...|[-5119.9522581968...|[0.0,1.0,0.0,2.25...|       1.0|\n",
      "|    1|(Sat) 17 Aug 2019...|    49|    48|2019|      1|        0|        1|        0|        0|  1|           0|           3|        0|        1|   -1|    0|   -1|      2|  Aug|       9.0|[1.0,49.0,48.0,20...|[-5134.5413984142...|[0.0,0.0,1.0,4.96...|       2.0|\n",
      "|    1|(Sat) 17 Aug 2019...|   216|   104|2019|      1|        4|        4|        1|        1|  0|           1|           1|        3|        3|    0|    0|    0|      3|  Aug|       9.0|[1.0,216.0,104.0,...|[-5136.1447957354...|[0.0,0.0,1.039827...|       3.0|\n",
      "|    1|(Sat) 18 Aug 2012...|   152|   134|2012|      1|        0|        1|        0|        0|  1|           0|           3|        0|        1|   -1|    0|   -1|      2|  Aug|       9.0|[1.0,152.0,134.0,...|[-5117.3093688592...|[0.0,0.0,1.0,1.06...|       2.0|\n",
      "|    1|(Sat) 18 Aug 2012...|   182|   100|2012|      1|        2|        1|        2|        0|  1|           3|           0|        0|        1|    1|    2|   -1|      1|  Aug|       9.0|[1.0,182.0,100.0,...|[-5117.4781995909...|[0.0,1.0,0.0,1.52...|       1.0|\n",
      "|    1|(Sat) 19 Aug 2017...|   152|   165|2017|      1|        2|        3|        1|        1|  1|           0|           3|        1|        2|   -1|    0|   -1|      2|  Aug|       9.0|[1.0,152.0,165.0,...|[-5130.5883369978...|[0.0,0.0,1.0,4.05...|       2.0|\n",
      "|    1|(Sat) 19 Aug 2017...|   182|   155|2017|      1|        1|        1|        1|        1|  0|           1|           1|        0|        0|    0|    0|    0|      3|  Aug|       9.0|[1.0,182.0,155.0,...|[-5130.3876514042...|   [0.0,0.0,0.0,1.0]|       3.0|\n",
      "|    1|(Sat) 20 Aug 2016...|   182|   155|2016|      1|        6|        4|        3|        3|  2|           3|           0|        3|        1|    2|    0|    2|      1|  Aug|       9.0|[1.0,182.0,155.0,...|[-5128.7392595400...|   [0.0,1.0,0.0,0.0]|       1.0|\n",
      "|    1|(Sat) 21 Aug 1999...|    30|   160|1999|      1|        1|        0|        0|        0|  1|           3|           0|        1|        0|    1|    0|    1|      1|  Aug|       9.0|[1.0,30.0,160.0,1...|[-5083.9611509901...|[0.0,1.0,0.0,2.17...|       1.0|\n",
      "|    1|(Sat) 21 Aug 1999...|   210|   164|1999|      1|        1|        2|        0|        1|  1|           0|           3|        1|        1|   -1|   -1|    0|      2|  Aug|       9.0|[1.0,210.0,164.0,...|[-5084.7932430785...|[0.0,0.0,1.0,4.05...|       2.0|\n",
      "|    1|(Sat) 23 Aug 2014...|   134|    30|2014|      1|        1|        0|        1|        0|  1|           3|           0|        0|        0|    1|    1|    0|      1|  Aug|       9.0|[1.0,134.0,30.0,2...|[-5121.9714404331...|[0.0,1.0,0.0,2.84...|       1.0|\n",
      "|    1|(Sat) 25 Aug 2001...|   210|   161|2001|      1|        1|        0|        1|        0|  1|           3|           0|        0|        0|    1|    1|    0|      1|  Aug|       9.0|[1.0,210.0,161.0,...|[-5089.5566487869...|[0.0,1.0,0.0,6.19...|       1.0|\n",
      "+-----+--------------------+------+------+----+-------+---------+---------+---------+---------+---+------------+------------+---------+---------+-----+-----+-----+-------+-----+----------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Round', 'Date', 'Team_1', 'Team_2', 'Year', 'Country', 'FT_Team_1', 'FT_Team_2', 'H1_Team_1', 'H1_Team_2', 'GGD', 'Team_1_(pts)', 'Team_2_(pts)', 'H2_Team_1', 'H2_Team_2', 'FT_GD', 'H1_GD', 'H2_GD', 'Outcome', 'Month', 'Game_Month', 'features', 'rawPrediction', 'probability', 'prediction']\n"
     ]
    }
   ],
   "source": [
    "print (y_pred.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+----------+\n",
      "|Outcome|       rawPrediction|         probability|prediction|\n",
      "+-------+--------------------+--------------------+----------+\n",
      "|      3|[-5132.4851158264...|   [0.0,0.0,0.0,1.0]|       3.0|\n",
      "|      2|[-5132.8649300937...|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|      1|[-5127.7750910015...|[0.0,1.0,0.0,2.61...|       1.0|\n",
      "|      2|[-5079.5944439100...|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|      1|[-5117.1766533205...|[0.0,1.0,0.0,2.00...|       1.0|\n",
      "|      2|[-5127.2188066969...|[0.0,0.0,1.0,2.63...|       2.0|\n",
      "|      3|[-5122.0905955839...|   [0.0,0.0,0.0,1.0]|       3.0|\n",
      "|      2|[-5102.4070137056...|[0.0,0.0,1.0,1.86...|       2.0|\n",
      "|      1|[-5119.9522581968...|[0.0,1.0,0.0,2.25...|       1.0|\n",
      "|      2|[-5134.5413984142...|[0.0,0.0,1.0,4.96...|       2.0|\n",
      "|      3|[-5136.1447957354...|[0.0,0.0,1.039827...|       3.0|\n",
      "|      2|[-5117.3093688592...|[0.0,0.0,1.0,1.06...|       2.0|\n",
      "|      1|[-5117.4781995909...|[0.0,1.0,0.0,1.52...|       1.0|\n",
      "|      2|[-5130.5883369978...|[0.0,0.0,1.0,4.05...|       2.0|\n",
      "|      3|[-5130.3876514042...|   [0.0,0.0,0.0,1.0]|       3.0|\n",
      "|      1|[-5128.7392595400...|   [0.0,1.0,0.0,0.0]|       1.0|\n",
      "|      1|[-5083.9611509901...|[0.0,1.0,0.0,2.17...|       1.0|\n",
      "|      2|[-5084.7932430785...|[0.0,0.0,1.0,4.05...|       2.0|\n",
      "|      1|[-5121.9714404331...|[0.0,1.0,0.0,2.84...|       1.0|\n",
      "|      1|[-5089.5566487869...|[0.0,1.0,0.0,6.19...|       1.0|\n",
      "+-------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred.select('Outcome','rawPrediction', 'probability', 'prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check accuracy\n",
    "multi_eval = MulticlassClassificationEvaluator(labelCol='Outcome',metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_eval.evaluate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
